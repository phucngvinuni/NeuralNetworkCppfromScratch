# NeuralNetworkCppfromScratch
### ü§ñ Neural Network l√† g√¨

Neural Network l√† m·ªôt ph∆∞∆°ng th·ª©c ph·ªï bi·∫øn trong lƒ©nh v·ª±c üåê tr√≠ tu·ªá nh√¢n t·∫°o, gi√∫p m√°y t√≠nh üñ•Ô∏è d·ª± ƒëo√°n, nh·∫≠n d·∫°ng v√† x·ª≠ l√Ω d·ªØ li·ªáu t∆∞∆°ng t·ª± nh∆∞ üß† b·ªô n√£o con ng∆∞·ªùi. Ph∆∞∆°ng th·ª©c n√†y c√≤n ƒë∆∞·ª£c g·ªçi l√† "deep learning" üìö, d·ª±a tr√™n vi·ªác k·∫øt n·ªëi c√°c n∆°-ron ho·∫∑c c√°c n√∫t v·ªõi nhau trong m·ªôt c·∫•u tr√∫c ph√¢n l·ªõp üï∏Ô∏è. Neural Network ƒë√£ ch·ª©ng minh kh·∫£ nƒÉng v∆∞·ª£t tr·ªôi trong vi·ªác x·ª≠ l√Ω d·ªØ li·ªáu l·ªõn v√† ph·ª©c t·∫°p, ƒë∆∞·ª£c ·ª©ng d·ª•ng r·ªông r√£i t·ª´ ph√¢n lo·∫°i h√¨nh ·∫£nh üì∑ ƒë·∫øn x·ª≠ l√Ω ng√¥n ng·ªØ t·ª± nhi√™n üìñ.

V·ªõi c∆° ch·∫ø n√†y, h·ªá th·ªëng c√≥ th·ªÉ t·ª± ph√°t hi·ªán v√† kh·∫Øc ph·ª•c c√°c l·ªói ‚ö†Ô∏è ƒë√£ x·∫£y ra th√¥ng qua vi·ªác t·ªëi ∆∞u h√≥a l·∫∑p ƒëi l·∫∑p l·∫°i üîÑ. Neural Network do ƒë√≥ c√≥ kh·∫£ nƒÉng gi·∫£i quy·∫øt c√°c v·∫•n ƒë·ªÅ ph·ª©c t·∫°p nh∆∞ nh·∫≠n di·ªán khu√¥n m·∫∑t üòäüì∏, t√≥m t·∫Øt t√†i li·ªáu üìÑ, v√† th·∫≠m ch√≠ d·ª± ƒëo√°n xu h∆∞·ªõng th·ªã tr∆∞·ªùng t√†i ch√≠nh üìàüí∏.

---

# 1. üõ†Ô∏è C·∫•u T·∫°o C·ªßa Neural Network

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0cd1a57e-1470-4b50-8a03-54a585466016/268d1e94-a2cb-4a37-8fa7-6a6b05d180ff/image.png)

M·ªói m·∫°ng n∆°-ron nh√¢n t·∫°o l√† m·ªôt perceptron ƒëa t·∫ßng v√† th∆∞·ªùng bao g·ªìm 3 lo·∫°i t·∫ßng ch√≠nh:

- **Input Layer (t·∫ßng ƒë·∫ßu v√†o):** Ti·∫øp nh·∫≠n d·ªØ li·ªáu ban ƒë·∫ßu üèóÔ∏è, ch·∫≥ng h·∫°n nh∆∞ h√¨nh ·∫£nh, √¢m thanh ho·∫∑c vƒÉn b·∫£n.
- **Output Layer (t·∫ßng ƒë·∫ßu ra):** Cho k·∫øt qu·∫£ x·ª≠ l√Ω cu·ªëi c√πng üì§, v√≠ d·ª•: ph√¢n lo·∫°i m·ªôt h√¨nh ·∫£nh l√† m√®o üê± ho·∫∑c ch√≥ üê∂.
- **Hidden Layer (t·∫ßng ·∫©n):** X·ª≠ l√Ω v√† suy lu·∫≠n th√¥ng qua c√°c li√™n k·∫øt n·ªôi gi·ªØa c√°c n∆°-ron üîÑ, th·ª±c hi·ªán c√°c t√≠nh to√°n ph·ª©c t·∫°p ƒë·ªÉ tr√≠ch xu·∫•t ƒë·∫∑c tr∆∞ng t·ª´ d·ªØ li·ªáu ƒë·∫ßu v√†o.

M·ªôt m·∫°ng Neural Network th∆∞·ªùng c√≥ 1 t·∫ßng ƒë·∫ßu v√†o v√† 1 t·∫ßng ƒë·∫ßu ra, nh∆∞ng s·ªë l∆∞·ª£ng t·∫ßng ·∫©n c√≥ th·ªÉ thay ƒë·ªïi t√πy thu·ªôc v√†o ƒë·ªô ph·ª©c t·∫°p c·ªßa b√†i to√°n üß©. S·ªë l∆∞·ª£ng n∆°-ron trong t·ª´ng t·∫ßng c≈©ng ƒë∆∞·ª£c thi·∫øt k·∫ø linh ho·∫°t ƒë·ªÉ t·ªëi ∆∞u h√≥a kh·∫£ nƒÉng x·ª≠ l√Ω üéõÔ∏è.

---

### 2. üìö Qu√° Tr√¨nh H·ªçc

Neural Network h·ªçc th√¥ng qua vi·ªác hu·∫•n luy·ªán d·ªØ li·ªáu üèãÔ∏è‚Äç‚ôÇÔ∏è, bao g·ªìm c√°c b∆∞·ªõc ch√≠nh nh∆∞ sau:

### 2.1. üöÄ Lan Truy·ªÅn Ti·∫øn (Forward Propagation)

D·ªØ li·ªáu ƒë∆∞·ª£c chuy·ªÉn ti·∫øn qua c√°c t·∫ßng, ƒë·∫øn khi t·∫°o ra k·∫øt qu·∫£ ƒë·∫ßu ra üìä. C√°c tham s·ªë nh∆∞ **tr·ªçng s·ªë (weights)** ‚öñÔ∏è v√† **bias** ‚öôÔ∏è ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ x√°c ƒë·ªãnh ƒë·ªô ·∫£nh h∆∞·ªüng c·ªßa t·ª´ng n∆°-ron. C√¥ng th·ª©c t√≠nh to√°n trong m·ªói n∆°-ron l√†:

$$
 z = f(W \cdot x + b) 
$$

Trong ƒë√≥:

- W : Ma tr·∫≠n tr·ªçng s·ªë ‚öñÔ∏è
- x: ƒê·∫ßu v√†o üéØ
- b: Bias ‚öôÔ∏è
- f : H√†m k√≠ch ho·∫°t üîë, v√≠ d·ª•: ReLU, Sigmoid

![image.png](https://prod-files-secure.s3.us-west-2.amazonaws.com/0cd1a57e-1470-4b50-8a03-54a585466016/f0cad791-2d7d-4bdb-a475-c6d2f8337970/image.png)

### 2.2. üîÑ Lan Truy·ªÅn Ng∆∞·ª£c (Back Propagation)

Khi k·∫øt qu·∫£ ƒë·∫ßu ra kh√¥ng ƒë·∫°t ƒë∆∞·ª£c mong mu·ªën ‚ùå, Neural Network s·∫Ω t√≠nh **gradient** c·ªßa l·ªói (loss) ƒë·ªÉ c·∫≠p nh·∫≠t l·∫°i tr·ªçng s·ªë theo h∆∞·ªõng:

$$
W_{new} = W_{old} - \eta \cdot \frac{\partial L}{\partial W}
$$

Trong ƒë√≥:

- eta: T·ªëc ƒë·ªô h·ªçc üö¥‚Äç‚ôÄÔ∏è (learning rate)
- C√°i ƒë·∫°o h√†m kia: Gradient c·ªßa h√†m l·ªói theo tr·ªçng s·ªë v√† bias üîç

ƒê·ªÉ hi·ªÉu th√™m v·ªÅ lan truy·ªÅn ng∆∞·ª£c, c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o b√†i vi·∫øt n√†y: https://dominhhai.github.io/vi/2018/04/nn-bp/

### 2.3. üèîÔ∏è Gradient Descent

Gradient Descent l√† ph∆∞∆°ng ph√°p t·ªëi ∆∞u h√≥a tr·ªçng s·ªë v√† bias trong m·∫°ng neural b·∫±ng c√°ch ƒëi·ªÅu ch·ªânh c√°c tham s·ªë d·ª±a tr√™n gradient c·ªßa h√†m m·∫•t m√°t üìâ. C√°c bi·∫øn th·ªÉ ph·ªï bi·∫øn nh∆∞ **Stochastic Gradient Descent (SGD)** üåÄ v√† **Adam Optimizer** ‚ö° ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ tƒÉng t·ªëc ƒë·ªô h·ªôi t·ª• v√† tr√°nh c√°c ƒëi·ªÉm c·ª±c ti·ªÉu c·ª•c b·ªô ‚õ∞Ô∏è, gi√∫p m·∫°ng neural h·ªçc hi·ªáu qu·∫£ h∆°n tr√™n d·ªØ li·ªáu hu·∫•n luy·ªán.

ƒê·ªÉ hi·ªÉu th√™m v·ªÅ lan truy·ªÅn ng∆∞·ª£c, c√°c b·∫°n c√≥ th·ªÉ tham kh·∫£o b√†i vi·∫øt n√†y: https://machinelearningcoban.com/2017/01/12/gradientdescent/

### 2.4. üßÆ H√†m Softmax

H√†m Softmax ch·ªß y·∫øu ƒë∆∞·ª£c s·ª≠ d·ª•ng trong c√°c b√†i to√°n ph√¢n lo·∫°i üóÇÔ∏è ƒë·ªÉ chuy·ªÉn k·∫øt qu·∫£ ƒë·∫ßu ra th√†nh d·∫°ng x√°c su·∫•t. C√¥ng th·ª©c c·ªßa h√†m l√†:

$$
 \sigma(z)i = \frac{e^{z_i}}{\sum{j=1}^{N} e^{z_j}} 
$$

Trong ƒë√≥:

- z_i: ƒêi·ªÉm s·ªë ch∆∞a chu·∫©n h√≥a c·ªßa l·ªõp üè∑Ô∏è
- N: T·ªïng s·ªë l·ªõp üì¶

H√†m Softmax ƒë·∫£m b·∫£o t·ªïng c√°c x√°c su·∫•t b·∫±ng 1, h·ªó tr·ª£ vi·ªác gi·∫£i th√≠ch v√† s·ª≠ d·ª•ng trong c√°c h√†m m·∫•t m√°t nh∆∞ Cross-Entropy Loss.

---

### 3. üéØ Loss Function (H√†m L·ªói)

Loss Function ƒë∆∞·ª£c s·ª≠ d·ª•ng ƒë·ªÉ ƒë√°nh gi√° ƒë·ªô ch√≠nh x√°c c·ªßa Neural Network ‚úÖ. C√°c h√†m loss ph·ªï bi·∫øn bao g·ªìm:

- **Mean Squared Error (MSE):**

$$

 L = \frac{1}{N} \sum_{i=1}^{N} (y_i - \hat{y}_i)^2 
$$

- **Cross-Entropy Loss:**

$$
 L = -\frac{1}{N} \sum_{i=1}^{N} y_i \log(\hat{y}_i) 
$$

H√†m loss gi√∫p h·ªá th·ªëng nh·∫≠n bi·∫øt s·ª± kh√°c bi·ªát gi·ªØa ƒë·∫ßu ra d·ª± ƒëo√°n v√† th·ª±c t·∫ø, l√†m c∆° s·ªü ƒë·ªÉ c·∫≠p nh·∫≠t tr·ªçng s·ªë üîÑ.

---

### 4. üèóÔ∏è Thi·∫øt K·∫ø L·ªõp ·∫®n

### 4.1. ‚öñÔ∏è Weight (Tr·ªçng S·ªë) v√† Bias

Tr·ªçng s·ªë ƒë·ªãnh ƒë·ªô quan tr·ªçng c·ªßa d·ªØ li·ªáu ƒë·∫ßu v√†o ƒë·ªëi v·ªõi k·∫øt qu·∫£. Bias gi√∫p ƒëi·ªÅu ch·ªânh ng∆∞·ª°ng k√≠ch ho·∫°t üìè, ƒë·∫£m b·∫£o h·ªá th·ªëng ho·∫°t ƒë·ªông hi·ªáu qu·∫£ ngay c·∫£ khi d·ªØ li·ªáu ƒë·∫ßu v√†o b·∫±ng 0.

### 4.2. üîë Activation Function (H√†m K√≠ch Ho·∫°t)

Trong Neural Network, h√†m k√≠ch ho·∫°t quy·∫øt ƒë·ªãnh c√°ch t·∫°o ra ƒë·∫ßu ra t·ª´ ƒë·∫ßu v√†o. C√°c h√†m ph·ªï bi·∫øn bao g·ªìm:

- **ReLU (Rectified Linear Unit):** ‚ö° TƒÉng t·ªëc qu√° tr√¨nh hu·∫•n luy·ªán b·∫±ng c√°ch lo·∫°i b·ªè gi√° tr·ªã √¢m.
- **Sigmoid:** üìà Chuy·ªÉn ƒë·ªïi gi√° tr·ªã ƒë·∫ßu v√†o th√†nh x√°c su·∫•t.
- **Tanh:** üìâ C√¢n ƒë·ªëi ƒë·∫ßu ra gi·ªØa \(-1\) v√† \(1\).

### 4.3. üßÆ Ph∆∞∆°ng Tr√¨nh L·ªõp ·∫®n

T·∫°i t·∫ßng ·∫©n, ph∆∞∆°ng tr√¨nh t√≠nh to√°n c√≥ d·∫°ng:

$$
h^{(l)} = f(W^{(l)} \cdot h^{(l-1)} + b^{(l)}) 
$$

Trong ƒë√≥ \( l \) l√† ch·ªâ s·ªë t·∫ßng hi·ªán t·∫°i üî¢.

---

# Coding

Th∆∞ vi·ªán Eigen

ƒê·ªÉ t√≠nh to√°n ma tr·∫≠n m·ªôt c√°ch hi·ªáu qu·∫£, m√¨nh s·ª≠ d·ª•ng th∆∞ vi·ªán Eigen. Chi ti·∫øt: https://eigen.tuxfamily.org/index.php?title=Main_Page

Dataset:

M√¨nh s·ª≠ d·ª•ng b·ªô dataset MNIST - m·ªôt b·ªô d·ªØ li·ªáu chu·∫©n v√† ph·ªï bi·∫øn trong machine learning. MNIST ch·ª©a c√°c ·∫£nh grayscale c·ªßa ch·ªØ s·ªë vi·∫øt tay t·ª´ 0-9. C√°c b·∫°n c√≥ th·ªÉ t·∫£i dataset n√†y t·ª´ Kaggle

Ki·∫øn tr√∫c d·ª± ki·∫øn:

1. Input Layer: 784 n∆°-ron (vector h√≥a ·∫£nh 28√ó28).
2. Hidden Layer 1: 128 n∆°-ron + **ReLU**.
3. Hidden Layer 2: 64 n∆°-ron + **ReLU** (tu·ª≥ ch·ªçn, n·∫øu mu·ªën m·∫°ng s√¢u h∆°n).
4. Output Layer: 10 n∆°-ron + **Softmax**.

H√†m activations

·ªû ƒë√¢y m√¨nh s·ª≠ d·ª•ng 2 h√†m l√† ReLU v√† Softmax, 

H√†m ReLu

- Gi·∫£i quy·∫øt v·∫•n ƒë·ªÅ **vanishing gradient**, gi√∫p hu·∫•n luy·ªán nhanh v√† ·ªïn ƒë·ªãnh h∆°n.
- D·ªÖ d√†ng tri·ªÉn khai v√† t√≠nh to√°n.

```cpp
    // ReLU Activation Function
    VectorXd relu(const VectorXd &v) {
        return v.array().max(0.0);
    }

    // Derivative of ReLU
    VectorXd relu_derivative(const VectorXd &v) {
        return (v.array() > 0.0).cast<double>();
    }
```

H√†m Softmax

Chuy·ªÉn c√°c ƒë·∫ßu ra th√†nh x√°c su·∫•t, gi√∫p d·ªÖ d√†ng x√°c ƒë·ªãnh ch·ªØ s·ªë ƒë∆∞·ª£c d·ª± ƒëo√°n (ch·ªØ s·ªë t∆∞∆°ng ·ª©ng v·ªõi x√°c su·∫•t cao nh·∫•t).

```cpp
    // Softmax Activation Function
    VectorXd softmax(const VectorXd &v) {
        VectorXd shifted_v = v.array() - v.maxCoeff();
        VectorXd exp_values = shifted_v.array().exp();
        return exp_values / exp_values.sum();
    }
```

Loss function

V·ªõi b√†i to√°n ph√¢n lo·∫°i, ta th∆∞·ªùng s·ª≠ d·ª•ng **Cross-Entropy Loss**:

$$
L = -\sum_{i=1}^{N} y_i \cdot \log(\hat{y}_i)
$$

Trong ƒë√≥:

- yi: nh√£n th·∫≠t (1-hot encoded)
- ≈∑i: x√°c su·∫•t d·ª± ƒëo√°n t·ª´ Softmax

Gradient c·ªßa Softmax + Cross-Entropy c√≥ d·∫°ng ƒë∆°n gi·∫£n:

$$
\frac{\partial L}{\partial z_j} = \hat{y}_j - y_j
$$

(·ªü ƒë√¢y zj l√† gi√° tr·ªã ƒë·∫ßu ra tr∆∞·ªõc Softmax)
